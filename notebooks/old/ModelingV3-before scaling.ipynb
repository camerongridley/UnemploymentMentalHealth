{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, plot_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from pandas.plotting import table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 8\n",
    "plt.rc('font', size=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I identify as having a mental illness</th>\n",
       "      <th>Education</th>\n",
       "      <th>I have my own computer separate from a smart phone</th>\n",
       "      <th>I have been hospitalized before for my mental illness</th>\n",
       "      <th>How many days were you hospitalized for your mental illness</th>\n",
       "      <th>I am legally disabled</th>\n",
       "      <th>I have my regular access to the internet</th>\n",
       "      <th>I live with my parents</th>\n",
       "      <th>I have a gap in my resume</th>\n",
       "      <th>Total gaps in resume in months</th>\n",
       "      <th>Annual income (including any social welfare programs) in USD</th>\n",
       "      <th>I am unemployed</th>\n",
       "      <th>I read outside of work and school</th>\n",
       "      <th>Annual income from social welfare programs</th>\n",
       "      <th>I receive food stamps</th>\n",
       "      <th>I am on section 8 housing</th>\n",
       "      <th>How many times were you hospitalized for your mental illness</th>\n",
       "      <th>Lack of concentration</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Obsessive_thinking</th>\n",
       "      <th>Mood_swings</th>\n",
       "      <th>Panic_attacks</th>\n",
       "      <th>Compulsive_behavior</th>\n",
       "      <th>Tiredness</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Household Income</th>\n",
       "      <th>Region_East North Central</th>\n",
       "      <th>Region_East South Central</th>\n",
       "      <th>Region_Middle Atlantic</th>\n",
       "      <th>Region_Mountain</th>\n",
       "      <th>Region_New England</th>\n",
       "      <th>Region_Pacific</th>\n",
       "      <th>Region_South Atlantic</th>\n",
       "      <th>Region_West North Central</th>\n",
       "      <th>Region_West South Central</th>\n",
       "      <th>Device Type_Android Phone / Tablet</th>\n",
       "      <th>Device Type_MacOS Desktop / Laptop</th>\n",
       "      <th>Device Type_Other</th>\n",
       "      <th>Device Type_Windows Desktop / Laptop</th>\n",
       "      <th>Device Type_iOS Phone / Tablet</th>\n",
       "      <th>time_to_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I identify as having a mental illness  Education  \\\n",
       "0                                      0          1   \n",
       "1                                      1          5   \n",
       "2                                      0          3   \n",
       "3                                      0          2   \n",
       "4                                      1          3   \n",
       "\n",
       "   I have my own computer separate from a smart phone  \\\n",
       "0                                                  0    \n",
       "1                                                  1    \n",
       "2                                                  1    \n",
       "3                                                  1    \n",
       "4                                                  1    \n",
       "\n",
       "   I have been hospitalized before for my mental illness  \\\n",
       "0                                                  0       \n",
       "1                                                  0       \n",
       "2                                                  0       \n",
       "3                                                  0       \n",
       "4                                                  1       \n",
       "\n",
       "   How many days were you hospitalized for your mental illness  \\\n",
       "0                                                  0             \n",
       "1                                                  0             \n",
       "2                                                  0             \n",
       "3                                                  0             \n",
       "4                                                 35             \n",
       "\n",
       "   I am legally disabled  I have my regular access to the internet  \\\n",
       "0                      0                                         1   \n",
       "1                      0                                         1   \n",
       "2                      0                                         1   \n",
       "3                      0                                         1   \n",
       "4                      1                                         1   \n",
       "\n",
       "   I live with my parents  I have a gap in my resume  \\\n",
       "0                       0                          1   \n",
       "1                       0                          0   \n",
       "2                       0                          0   \n",
       "3                       1                          1   \n",
       "4                       0                          1   \n",
       "\n",
       "   Total gaps in resume in months  \\\n",
       "0                              24   \n",
       "1                               1   \n",
       "2                               0   \n",
       "3                              11   \n",
       "4                              33   \n",
       "\n",
       "   Annual income (including any social welfare programs) in USD  \\\n",
       "0                                                 35              \n",
       "1                                                 22              \n",
       "2                                                100              \n",
       "3                                                  0              \n",
       "4                                                 32              \n",
       "\n",
       "   I am unemployed  I read outside of work and school  \\\n",
       "0                1                                  1   \n",
       "1                0                                  1   \n",
       "2                0                                  1   \n",
       "3                1                                  1   \n",
       "4                0                                  1   \n",
       "\n",
       "   Annual income from social welfare programs  I receive food stamps  \\\n",
       "0                                           0                      0   \n",
       "1                                           0                      0   \n",
       "2                                           0                      0   \n",
       "3                                           0                      0   \n",
       "4                                          30                      0   \n",
       "\n",
       "   I am on section 8 housing  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "   How many times were you hospitalized for your mental illness  \\\n",
       "0                                                  0              \n",
       "1                                                  0              \n",
       "2                                                  0              \n",
       "3                                                  0              \n",
       "4                                                  4              \n",
       "\n",
       "   Lack of concentration  Anxiety  Depression  Obsessive_thinking  \\\n",
       "0                      1        1           1                   1   \n",
       "1                      1        1           1                   0   \n",
       "2                      0        0           0                   0   \n",
       "3                      0        0           0                   0   \n",
       "4                      1        1           1                   1   \n",
       "\n",
       "   Mood_swings  Panic_attacks  Compulsive_behavior  Tiredness  Age  Gender  \\\n",
       "0            0              1                    0          0    1       0   \n",
       "1            0              1                    0          1    0       0   \n",
       "2            0              0                    0          0    1       0   \n",
       "3            0              0                    0          0    1       0   \n",
       "4            1              1                    1          1    1       0   \n",
       "\n",
       "   Household Income  Region_East North Central  Region_East South Central  \\\n",
       "0                 3                        0.0                        0.0   \n",
       "1                 4                        0.0                        1.0   \n",
       "2                 8                        0.0                        0.0   \n",
       "3                 3                        0.0                        0.0   \n",
       "4                 3                        1.0                        0.0   \n",
       "\n",
       "   Region_Middle Atlantic  Region_Mountain  Region_New England  \\\n",
       "0                     0.0              1.0                 0.0   \n",
       "1                     0.0              0.0                 0.0   \n",
       "2                     0.0              0.0                 0.0   \n",
       "3                     0.0              0.0                 1.0   \n",
       "4                     0.0              0.0                 0.0   \n",
       "\n",
       "   Region_Pacific  Region_South Atlantic  Region_West North Central  \\\n",
       "0             0.0                    0.0                        0.0   \n",
       "1             0.0                    0.0                        0.0   \n",
       "2             1.0                    0.0                        0.0   \n",
       "3             0.0                    0.0                        0.0   \n",
       "4             0.0                    0.0                        0.0   \n",
       "\n",
       "   Region_West South Central  Device Type_Android Phone / Tablet  \\\n",
       "0                        0.0                                 1.0   \n",
       "1                        0.0                                 0.0   \n",
       "2                        0.0                                 0.0   \n",
       "3                        0.0                                 0.0   \n",
       "4                        0.0                                 0.0   \n",
       "\n",
       "   Device Type_MacOS Desktop / Laptop  Device Type_Other  \\\n",
       "0                                 0.0                0.0   \n",
       "1                                 1.0                0.0   \n",
       "2                                 1.0                0.0   \n",
       "3                                 0.0                0.0   \n",
       "4                                 0.0                0.0   \n",
       "\n",
       "   Device Type_Windows Desktop / Laptop  Device Type_iOS Phone / Tablet  \\\n",
       "0                                   0.0                             0.0   \n",
       "1                                   0.0                             0.0   \n",
       "2                                   0.0                             0.0   \n",
       "3                                   1.0                             0.0   \n",
       "4                                   0.0                             1.0   \n",
       "\n",
       "   time_to_complete  \n",
       "0             188.0  \n",
       "1              65.0  \n",
       "2             141.0  \n",
       "3              77.0  \n",
       "4             142.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "encoded_df = pd.read_pickle('../data/encoded_df.pkl')\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Numeric Columns for Scaling\n",
    "- excluding binary cols and categorical cols that have been encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = ['How many days were you hospitalized for your mental illness',\n",
    "                     'Total gaps in resume in months',\n",
    "                     'Annual income (including any social welfare programs) in USD',\n",
    "                     'Annual income from social welfare programs',\n",
    "                     'How many times were you hospitalized for your mental illness',\n",
    "                     'time_to_complete'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for properly scaling the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A good replacement for this function would be to use the ColumnTransformer with a Pipeline\n",
    "# Though since this data needed such complicated cleaning, it seemed appropriate to handle this way\n",
    "def scale_and_merge(traing_data, test_data, cols_to_scale):\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled_features = scaler.fit_transform(traing_data[cols_to_scale])\n",
    "    train_scaled_features_df = pd.DataFrame(train_scaled_features, columns=cols_to_scale)\n",
    "    \n",
    "    training_scaled_df = traing_data.drop(features_to_scale, axis=1)\n",
    "    training_scaled_df = pd.merge(training_scaled_df, train_scaled_features_df, right_index=True, left_index=True)\n",
    "    \n",
    "    test_scaled_features = scaler.transform(test_data[cols_to_scale])\n",
    "    test_scaled_features_df = pd.DataFrame(test_scaled_features, columns=cols_to_scale)\n",
    "    \n",
    "    test_scaled_df = test_data.drop(features_to_scale, axis=1)\n",
    "    test_scaled_df = pd.merge(test_scaled_df, test_scaled_features_df, right_index=True, left_index=True)\n",
    "    \n",
    "    return training_scaled_df, test_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: Can we predict unemployment from mental health data?\n",
    "### Target: 'I am unemployed'\n",
    "\n",
    "#### V1 - using all features in cleaned df\n",
    "\n",
    "###### Notes:\n",
    "Stratify the train-test split to ensure even distribution of classes between the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 13\n",
    "\n",
    "y = encoded_df['I am unemployed']\n",
    "X = encoded_df.drop('I am unemployed', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=random_seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_fitted_model(model, X_test, y_test, file_name=None, title=None):\n",
    "    target_labels = ['Employed', 'Unemployed']\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "    score_types = {'Accuracy':accuracy_score,'Precision':precision_score, 'Recall':recall_score, 'F1':f1_score}\n",
    "    \n",
    "    for metric_name, metric_func in score_types.items():\n",
    "        print(f'{metric_name}: {round(metric_func(y_test, y_hat),2)}')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    if title: \n",
    "        ax.set_title(title)\n",
    "        \n",
    "    plot_confusion_matrix(model, X_test, y_test, display_labels=target_labels, ax=ax)\n",
    "    if file_name:\n",
    "        plt.savefig(f'../img/{file_name}.png', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    #print(classification_report(y_true=y_test, y_pred=y_hat, target_names=target_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled  = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "score_fitted_model(lr, X_test_scaled, y_test, file_name='conf_mat_baseline_log_reg', title='Baseline Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_scaled[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=random_seed)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "score_fitted_model(rf_clf, X_test, y_test, file_name='conf_mat_baseline_rand_for', title='Baseline Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(index=X.columns, data=rf_clf.feature_importances_).sort_values(ascending=False)[:10].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pd_table(save_df, fsize, filename):\n",
    "    fig, ax = plt.subplots(figsize=(8,3)) # set size frame\n",
    "    ax.xaxis.set_visible(False)  # hide the x axis\n",
    "    ax.yaxis.set_visible(False)  # hide the y axis\n",
    "    ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "    tabla = table(ax, save_df, loc='upper right', colWidths=[.2]*len(save_df.columns))\n",
    "    tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "    tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "    tabla.scale(1.2, 1.2) # change size table\n",
    "    #plt.savefig('table.png', transparent=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = pd.DataFrame(index=X.columns, data=rf_clf.feature_importances_, columns=['importance']).sort_values(by='importance', ascending=False)[:10].round(3)\n",
    "print_pd_table(save_df, (8,3), '../img/baseline_feature_importance2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting results.\n",
    "##### Accuracy and precision are pretty good, but the recall score is not. \n",
    "What is the best metric for this case? The cost of a false positive, i.e. predicting someone will become unemployed but they don't, is not likely a great concern, so precision is going to be primary.\n",
    "\n",
    "On the other hand, a false negative of predicing a person won't become unemployed but does, would mostly likely be a case we would want to avoid the most. Therefore, recall is more important than precision or accuracy.\n",
    "\n",
    "F1 is a balance of recall and precision. As expected it is somewhere inbetween the two, but it is most helpful in situations where there is a class imbalance and there are more actual negatives. This is the case with our data where we have about a 3:1 ratio of negative to positive target responses. So the F1 score may be the best score for our case.\n",
    "\n",
    "First, let's use cross validation to see if these results hold up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2 - Hyperparameter Tuning with All Features in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(X, y, pipe, params):\n",
    "    gridsearch = GridSearchCV(estimator=pipe, param_grid=params, scoring='f1', verbose=2, n_jobs=-1).fit(X, y)\n",
    "    print(f'Best F1 Score: {gridsearch.score(X, y)}')\n",
    "    \n",
    "    best_params = gridsearch.best_params_\n",
    "    print(best_params)\n",
    "    \n",
    "    return gridsearch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', LogisticRegression(max_iter=600, random_state=random_seed))\n",
    "])\n",
    "\n",
    "# define parameter ranges in dict\n",
    "# use double underscore to link pipline object with param name -\n",
    "# - use the label created when defining the pipe for the test left of the '__'\n",
    "params_lr = {\n",
    "    'estimator__solver' : ['lbfgs','liblinear', 'saga'],\n",
    "    'estimator__penalty' : ['l1','l2','elasticnet'],\n",
    "    'estimator__class_weight' : ['balanced', None]\n",
    "}\n",
    "\n",
    "gridpipe_lr = tune_model(X_train_scaled, y_train, pipe_lr, params_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_fitted_model(gridpipe_lr, X_test_scaled, y_test, file_name=None, title='Logistic Regression Gridsearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline(steps=[\n",
    "    ## RandomForests/Decision Trees don't benefit from scaling('scaler', StandardScaler()),\n",
    "    ('estimator', RandomForestClassifier(random_state=random_seed))\n",
    "])\n",
    "\n",
    "# define parameter ranges in dict\n",
    "# use double underscore to link pipline object with param name -\n",
    "# - use the label created when defining the pipe for the test left of the '__'\n",
    "params_rf = {\n",
    "    'estimator__n_estimators' : np.arange(40, 111, 10),\n",
    "    'estimator__max_depth' : np.arange(8, 20, 1),\n",
    "    'estimator__max_features' : ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "gridpipe_rf = tune_model(X_train, y_train, pipe_rf, params_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_fitted_model(gridpipe_rf, X_test, y_test, title='Random Forest Gridsearch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results So Far\n",
    "The logistic regression is outperforming the RandomForest, which appears to be overfitting. Gridsearch improved recal for the Logistic Regression model by .12 and did not help improve the Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove all income data because of possible colinearity.\n",
    "And date data, device type and hospitalizations because of low correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_me = [\n",
    "           'Annual income (including any social welfare programs) in USD',\n",
    "           'Annual income from social welfare programs',\n",
    "           'I have been hospitalized before for my mental illness', \n",
    "           'How many days were you hospitalized for your mental illness',\n",
    "           'I have a gap in my resume'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X.drop(columns=drop_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_reduced, y, test_size = .2, random_state=random_seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(random_state=random_seed)\n",
    "scaler = StandardScaler()\n",
    "X_train_red_scaled  = scaler.fit_transform(X_train_red)\n",
    "X_test_red_scaled = scaler.transform(X_test_red)\n",
    "\n",
    "lr2.fit(X_train_red_scaled, y_train_red)\n",
    "\n",
    "score_fitted_model(lr2, X_test_red_scaled, y_test_red, title='Logistic Regression X Reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridpipe_lr2 = tune_model(X_train_red_scaled, y_train_red, pipe_lr, params_lr)\n",
    "score_fitted_model(gridpipe_lr2, X_test_red_scaled, y_test_red, title='Logistic Regression Grid Search X Reduced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V3 - Using Recusive Feature Elimination To Find Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_best_num_of_features(model, rfecv, rfe_scoring, base_filename):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.title(f'{model.__class__.__name__} Recusive Feature Elimination with CV Results' )\n",
    "    plt.xlabel('Num of features selected', fontsize=12, labelpad=20)\n",
    "    plt.ylabel(f'{rfe_scoring.capitalize()} Score',fontsize=12, labelpad=20)\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, linewidth=3)\n",
    "    plt.savefig(f'../img/{base_filename}_rfe_num_features.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Optimal number of features: {}'.format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_rfe_features(X, rfecv):\n",
    "    M = np.array([X.columns, rfecv.ranking_])\n",
    "    df_rfe = pd.DataFrame(data=M.T, columns=['feature', 'ranking'])\n",
    "    \n",
    "    top_features = df_rfe[df_rfe['ranking']==1]\n",
    "    display(top_features)\n",
    "    \n",
    "    X_most_imp = X[top_features['feature']].copy()\n",
    "    \n",
    "    return X_most_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rfe(X, y, model, base_filename, rfe_scoring='f1', scale_features=False):\n",
    "    rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(10), scoring=rfe_scoring, n_jobs=-1)\n",
    "    \n",
    "    # this step is undesireable - scaling the entire X matrix will create data leakage - but I can't figure out how to scale within the RFECV process\n",
    "    if scale_features:\n",
    "        X2 = StandardScaler().fit_transform(X)\n",
    "        rfecv.fit(X2, y)\n",
    "    else:\n",
    "        X2 = X.copy()\n",
    "        \n",
    "    rfecv.fit(X2, y)\n",
    "    \n",
    "    plot_best_num_of_features(model, rfecv, rfe_scoring, base_filename)\n",
    "        \n",
    "    # Here we use the original X data so that proper scaling can occur if needed\n",
    "    X_most_imp = get_top_rfe_features(X, rfecv)\n",
    "    \n",
    "    X_train_rfe, X_test_rfe, y_train_rfe, y_test_rfe = train_test_split(X_most_imp, y, test_size = .2, random_state=random_seed, stratify=y)\n",
    "\n",
    "    if scale_features:\n",
    "        scaler_rfe = StandardScaler()\n",
    "        X_train_rfe  = scaler_rfe.fit_transform(X_train_rfe)\n",
    "        X_test_rfe = scaler_rfe.transform(X_test_rfe)\n",
    "        \n",
    "    model.fit(X_train_rfe, y_train_rfe)\n",
    "    print('Re-run the model with only the most important features of the same train-test split data used in the previous modeling so we can accurately compare the results.')\n",
    "    print('')\n",
    "    score_fitted_model(model, X_test_rfe, y_test_rfe, file_name=f'{base_filename}_conf_mat_rfe', title=f'{model.__class__.__name__} with RFECV')\n",
    "    \n",
    "    return X_most_imp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFECV with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_most_imp_rand_for = run_rfe(X, y, RandomForestClassifier(random_state=random_seed), base_filename='rand_forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice the engineered feature, \"time_to_complete\" is one of the most important\n",
    "\n",
    "### RFECV with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_most_imp_log_reg = run_rfe(X, y, LogisticRegression(random_state=random_seed), base_filename='logistic_regression', scale_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does Hyperparameter tuning with Gridsearch help the Random Forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_most_imp = X[X_most_imp_rand_for].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreating the train test split from the RFECV function\n",
    "X_train_rfe, X_test_rfe, y_train_rfe, y_test_rfe = train_test_split(X_most_imp, y, test_size = .2, random_state=random_seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf_rfe = Pipeline(steps=[\n",
    "    ## RandomForests/Decision Trees don't benefit from scaling('scaler', StandardScaler()),\n",
    "    ('estimator', RandomForestClassifier(random_state=random_seed))\n",
    "])\n",
    "\n",
    "# define parameter ranges in dict\n",
    "# use double underscore to link pipline object with param name -\n",
    "# - use the label created when defining the pipe for the test left of the '__'\n",
    "params_rf_rfe = {\n",
    "    'estimator__n_estimators' : np.arange(40, 111, 10),\n",
    "    'estimator__max_depth' : np.arange(8, 20, 1),\n",
    "    'estimator__max_features' : ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "gridpipe_rf_rfe = tune_model(X_train_rfe, y_train_rfe, pipe_rf_rfe, params_rf_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "score_fitted_model(gridpipe_rf_rfe, X_test_rfe, y_test_rfe, file_name='conf_mat_rfe_gridsearch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No, it doesn't improve things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv_rf(X, y):\n",
    "    pipe = make_pipeline(RandomForestClassifier())\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=11, shuffle=True)\n",
    "    scores = cross_val_score(pipe, X, y, cv=skf, scoring='accuracy')\n",
    "    print(f'Accuracy Scores: {scores}')\n",
    "    print(f'\\tMean:{scores.mean()}')\n",
    "    scores = cross_val_score(pipe, X, y, cv=skf, scoring='recall')\n",
    "    print(f'Recall Scores: {scores}')\n",
    "    print(f'\\tMean:{scores.mean()}')\n",
    "    scores = cross_val_score(pipe, X, y, cv=skf, scoring='f1')\n",
    "    print(f'F1 Scores: {scores}')\n",
    "    print(f'\\tMean:{scores.mean()}')\n",
    "\n",
    "run_cv_rf(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Additional Steps\n",
    "- PCA?\n",
    "- Oversampling to balance classes?\n",
    "- Turn buckets into averages instead of OneHotEncoding?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
